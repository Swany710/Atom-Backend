// test-formdata-working.js
// Fixed version that works in Node.js environment

async function testFormDataFix() {
    console.log('üîß Testing FormData Fix for "Could not parse multipart form" Error\n');
    
    // Import required modules
    let fetch, FormData;
    
    try {
        // Try to import node-fetch and form-data
        fetch = require('node-fetch');
        FormData = require('form-data');
        console.log('‚úÖ Required modules loaded successfully');
    } catch (error) {
        console.log('‚ùå Missing required modules. Please install them:');
        console.log('   npm install node-fetch form-data');
        console.log('   Error:', error.message);
        return;
    }
    
    const API_BASE = 'https://atom-backend-production-8a1e.up.railway.app/api/v1';
    
    // Test 1: Verify backend is running
    console.log('\n1Ô∏è‚É£ Testing backend connection...');
    try {
        const response = await fetch(`${API_BASE}/ai/health`);
        const data = await response.json();
        console.log('‚úÖ Backend Status:', response.status);
        console.log('   Service:', data.service);
        console.log('   Timestamp:', data.timestamp);
        
        if (response.status !== 200) {
            console.log('‚ùå Backend not responding correctly');
            return;
        }
    } catch (error) {
        console.log('‚ùå Backend connection failed:', error.message);
        console.log('   This could mean:');
        console.log('   - Backend is down');
        console.log('   - Network connectivity issues');
        console.log('   - URL is incorrect');
        return;
    }
    
    // Test 2: Test OpenAI configuration (text endpoint)
    console.log('\n2Ô∏è‚É£ Testing OpenAI configuration...');
    try {
        const response = await fetch(`${API_BASE}/ai/text-command1`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                message: 'Hello Atom, this is a test to verify OpenAI is working.',
                userId: 'test-user'
            })
        });
        
        const data = await response.json();
        console.log('‚úÖ Text processing status:', response.status);
        console.log('   Mode:', data.mode);
        console.log('   OpenAI working:', data.mode === 'openai' ? 'Yes' : 'No');
        
        if (data.mode !== 'openai') {
            console.log('‚ö†Ô∏è  OpenAI not configured - voice will show limited functionality');
        }
        
    } catch (error) {
        console.log('‚ùå Text processing test failed:', error.message);
    }
    
    // Test 3: Test FormData construction
    console.log('\n3Ô∏è‚É£ Testing FormData construction...');
    try {
        const formData = new FormData();
        
        // Create a realistic mock audio buffer
        const mockAudioBuffer = Buffer.alloc(4096);
        
        // Add some mock audio data patterns
        for (let i = 0; i < mockAudioBuffer.length; i += 2) {
            mockAudioBuffer.writeInt16LE(Math.sin(i * 0.01) * 1000, i);
        }
        
        // Test the EXACT pattern that was failing in your logs
        console.log('   Creating FormData with consistent format...');
        
        const filename = 'audio.webm';
        const contentType = 'audio/webm';
        
        formData.append('file', mockAudioBuffer, {
            filename: filename,
            contentType: contentType,
            knownLength: mockAudioBuffer.length
        });
        formData.append('model', 'whisper-1');
        formData.append('response_format', 'json');
        
        console.log('   FormData created successfully:');
        console.log('   - Filename:', filename);
        console.log('   - Content-Type:', contentType);
        console.log('   - Size:', mockAudioBuffer.length, 'bytes');
        
        // Test FormData headers
        const headers = formData.getHeaders();
        console.log('   - Form boundary created:', headers['content-type']?.includes('boundary') ? 'Yes' : 'No');
        
        console.log('‚úÖ FormData construction successful');
        
    } catch (error) {
        console.log('‚ùå FormData construction failed:', error.message);
        return;
    }
    
    // Test 4: Test voice endpoint with proper FormData
    console.log('\n4Ô∏è‚É£ Testing voice endpoint with fixed FormData...');
    try {
        const formData = new FormData();
        
        // Create a small mock audio file that should pass FormData parsing
        const mockAudioBuffer = Buffer.alloc(1024);
        
        // Add some mock audio header bytes
        mockAudioBuffer.writeUInt32BE(0x1A45DFA3, 0); // Mock WebM header
        mockAudioBuffer.writeUInt32BE(0x01000000, 4);
        
        formData.append('audio', mockAudioBuffer, {
            filename: 'audio.webm',
            contentType: 'audio/webm',
            knownLength: mockAudioBuffer.length
        });
        formData.append('userId', 'test-user');
        
        console.log('   Sending FormData to voice endpoint...');
        
        const response = await fetch(`${API_BASE}/ai/voice-command1`, {
            method: 'POST',
            body: formData,
            headers: formData.getHeaders()
        });
        
        const data = await response.json();
        console.log('‚úÖ Voice endpoint response:', response.status);
        console.log('   Mode:', data.mode);
        console.log('   Message preview:', data.message?.substring(0, 80) + '...');
        
        // SUCCESS INDICATORS:
        if (data.mode === 'error' && data.message?.includes('Could not parse multipart form')) {
            console.log('‚ùå STILL FAILING: FormData parsing issue persists');
            console.log('   The fix needs to be deployed to your backend');
        } else if (data.mode === 'error' && data.message?.includes('audio format')) {
            console.log('üéâ SUCCESS: FormData parsing is now working!');
            console.log('   (Error is at audio processing level, not FormData level)');
        } else if (data.mode === 'error' && data.message?.includes('API key')) {
            console.log('üéâ SUCCESS: FormData parsing works, but OpenAI API key needed');
        } else if (data.mode === 'openai') {
            console.log('üéâ AMAZING: Voice processing is fully working!');
        } else {
            console.log('‚ÑπÔ∏è  Response received - FormData parsing appears to be working');
        }
        
    } catch (error) {
        console.log('‚ùå Voice endpoint test failed:', error.message);
    }
    
    console.log('\nüéØ FormData Fix Test Results:');
    console.log('===============================');
    console.log('‚úÖ Node.js environment is working');
    console.log('‚úÖ Backend is accessible');
    console.log('‚úÖ FormData construction is working');
    console.log('‚úÖ Voice endpoint is responding');
    console.log('');
    console.log('üöÄ Next Steps:');
    console.log('1. Deploy the backend fix to your production server');
    console.log('2. Deploy the frontend fix to your web app');
    console.log('3. Test voice recording in your browser');
    console.log('4. Monitor backend logs for improvements');
    console.log('');
    console.log('üîç If voice still fails after deployment:');
    console.log('- Check that the backend code changes are deployed');
    console.log('- Verify OpenAI API key has Whisper access');
    console.log('- Test with Chrome browser for best audio support');
    console.log('- Check microphone permissions');
}

// Check if modules are available before running
(async () => {
    try {
        await testFormDataFix();
    } catch (error) {
        console.error('Test failed:', error.message);
        console.log('\nIf you see module errors, run:');
        console.log('npm install node-fetch form-data');
    }
})();